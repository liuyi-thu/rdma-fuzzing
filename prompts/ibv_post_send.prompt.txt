请补全以下函数对应的verb描述（用在verbs.py中）：

- ibv_post_send

请直接生成python代码，我之后会自行添加到verbs.py中。
函数详细信息：
Function Name: ibv_post_send
Output:
int ibv_post_send(struct ibv_qp * qp, struct ibv_send_wr * wr, struct ibv_send_wr ** bad_wr);
struct ibv_qp {
    struct ibv_context * context;
    struct ibv_context {
        struct ibv_device * device;
        struct ibv_device {
            struct _ibv_device_ops _ops;
            struct _ibv_device_ops {
                struct ibv_context *(*)(struct ibv_device *, int) _dummy1;
                void (*)(struct ibv_context *) _dummy2;
            };
            enum ibv_node_type node_type;
            enum ibv_node_type {
                IBV_NODE_UNKNOWN = -1,
                IBV_NODE_CA = 1,
                IBV_NODE_SWITCH = 2,
                IBV_NODE_ROUTER = 3,
                IBV_NODE_RNIC = 4,
                IBV_NODE_USNIC = 5,
                IBV_NODE_USNIC_UDP = 6,
                IBV_NODE_UNSPECIFIED = 7,
            };
            enum ibv_transport_type transport_type;
            enum ibv_transport_type {
                IBV_TRANSPORT_UNKNOWN = -1,
                IBV_TRANSPORT_IB = 0,
                IBV_TRANSPORT_IWARP = 1,
                IBV_TRANSPORT_USNIC = 2,
                IBV_TRANSPORT_USNIC_UDP = 3,
                IBV_TRANSPORT_UNSPECIFIED = 4,
            };
            char[64] name;
            char[64] dev_name;
            char[256] dev_path;
            char[256] ibdev_path;
        };
        struct ibv_context_ops ops;
        struct ibv_context_ops {
            int (*)(struct ibv_context *, struct ibv_device_attr *) _compat_query_device;
            int (*)(struct ibv_context *, uint8_t, struct _compat_ibv_port_attr *) _compat_query_port;
            void *(*)(void) _compat_alloc_pd;
            void *(*)(void) _compat_dealloc_pd;
            void *(*)(void) _compat_reg_mr;
            void *(*)(void) _compat_rereg_mr;
            void *(*)(void) _compat_dereg_mr;
            struct ibv_mw *(*)(struct ibv_pd *, enum ibv_mw_type) alloc_mw;
            int (*)(struct ibv_qp *, struct ibv_mw *, struct ibv_mw_bind *) bind_mw;
            int (*)(struct ibv_mw *) dealloc_mw;
            void *(*)(void) _compat_create_cq;
            int (*)(struct ibv_cq *, int, struct ibv_wc *) poll_cq;
            int (*)(struct ibv_cq *, int) req_notify_cq;
            void *(*)(void) _compat_cq_event;
            void *(*)(void) _compat_resize_cq;
            void *(*)(void) _compat_destroy_cq;
            void *(*)(void) _compat_create_srq;
            void *(*)(void) _compat_modify_srq;
            void *(*)(void) _compat_query_srq;
            void *(*)(void) _compat_destroy_srq;
            int (*)(struct ibv_srq *, struct ibv_recv_wr *, struct ibv_recv_wr **) post_srq_recv;
            void *(*)(void) _compat_create_qp;
            void *(*)(void) _compat_query_qp;
            void *(*)(void) _compat_modify_qp;
            void *(*)(void) _compat_destroy_qp;
            int (*)(struct ibv_qp *, struct ibv_send_wr *, struct ibv_send_wr **) post_send;
            int (*)(struct ibv_qp *, struct ibv_recv_wr *, struct ibv_recv_wr **) post_recv;
            void *(*)(void) _compat_create_ah;
            void *(*)(void) _compat_destroy_ah;
            void *(*)(void) _compat_attach_mcast;
            void *(*)(void) _compat_detach_mcast;
            void *(*)(void) _compat_async_event;
        };
        int cmd_fd;
        int async_fd;
        int num_comp_vectors;
        pthread_mutex_t mutex;
        void * abi_compat;
    };
    void * qp_context;
    struct ibv_pd * pd;
    struct ibv_pd {
        struct ibv_context * context;
        uint32_t handle;
    };
    struct ibv_cq * send_cq;
    struct ibv_cq {
        struct ibv_context * context;
        struct ibv_comp_channel * channel;
        struct ibv_comp_channel {
            struct ibv_context * context;
            int fd;
            int refcnt;
        };
        void * cq_context;
        uint32_t handle;
        int cqe;
        pthread_mutex_t mutex;
        pthread_cond_t cond;
        uint32_t comp_events_completed;
        uint32_t async_events_completed;
    };
    struct ibv_cq * recv_cq;
    struct ibv_srq * srq;
    struct ibv_srq {
        struct ibv_context * context;
        void * srq_context;
        struct ibv_pd * pd;
        uint32_t handle;
        pthread_mutex_t mutex;
        pthread_cond_t cond;
        uint32_t events_completed;
    };
    uint32_t handle;
    uint32_t qp_num;
    enum ibv_qp_state state;
    enum ibv_qp_state {
        IBV_QPS_RESET = 0,
        IBV_QPS_INIT = 1,
        IBV_QPS_RTR = 2,
        IBV_QPS_RTS = 3,
        IBV_QPS_SQD = 4,
        IBV_QPS_SQE = 5,
        IBV_QPS_ERR = 6,
        IBV_QPS_UNKNOWN = 7,
    };
    enum ibv_qp_type qp_type;
    enum ibv_qp_type {
        IBV_QPT_RC = 2,
        IBV_QPT_UC = 3,
        IBV_QPT_UD = 4,
        IBV_QPT_RAW_PACKET = 8,
        IBV_QPT_XRC_SEND = 9,
        IBV_QPT_XRC_RECV = 10,
        IBV_QPT_DRIVER = 255,
    };
    pthread_mutex_t mutex;
    pthread_cond_t cond;
    uint32_t events_completed;
};
struct ibv_send_wr {
    uint64_t wr_id;
    struct ibv_send_wr * next;
    struct ibv_sge * sg_list;
    struct ibv_sge {
        uint64_t addr;
        uint32_t length;
        uint32_t lkey;
    };
    int num_sge;
    enum ibv_wr_opcode opcode;
    enum ibv_wr_opcode {
        IBV_WR_RDMA_WRITE = 0,
        IBV_WR_RDMA_WRITE_WITH_IMM = 1,
        IBV_WR_SEND = 2,
        IBV_WR_SEND_WITH_IMM = 3,
        IBV_WR_RDMA_READ = 4,
        IBV_WR_ATOMIC_CMP_AND_SWP = 5,
        IBV_WR_ATOMIC_FETCH_AND_ADD = 6,
        IBV_WR_LOCAL_INV = 7,
        IBV_WR_BIND_MW = 8,
        IBV_WR_SEND_WITH_INV = 9,
        IBV_WR_TSO = 10,
        IBV_WR_DRIVER1 = 11,
        IBV_WR_FLUSH = 14,
        IBV_WR_ATOMIC_WRITE = 15,
    };
    unsigned int send_flags;
    union (unnamed union at verbs.h:1164:2) wr;
    union (unnamed union at verbs.h:1181:2) qp_type;
};

函数相关文档：
---
date: 2006-10-31
section: 3
title: IBV_POST_SEND
---

# NAME

ibv_post_send - post a list of work requests (WRs) to a send queue

# SYNOPSIS

    #include <infiniband/verbs.h>

    int ibv_post_send(struct ibv_qp *qp, struct ibv_send_wr *wr,
     struct ibv_send_wr **bad_wr);

# DESCRIPTION

**ibv_post_send()** posts the linked list of work requests (WRs)
starting with *wr* to the send queue of the queue pair *qp.* It stops
processing WRs from this list at the first failure (that can be detected
immediately while requests are being posted), and returns this failing
WR through *bad_wr.*

The argument *wr* is an ibv_send_wr struct, as defined in
\<infiniband/verbs.h\>.

    struct ibv_send_wr {
    uint64_t                wr_id;                  /* User defined WR ID */
    struct ibv_send_wr     *next;                   /* Pointer to next WR in list, NULL if last WR */
    struct ibv_sge         *sg_list;                /* Pointer to the s/g array */
    int                     num_sge;                /* Size of the s/g array */
    enum ibv_wr_opcode      opcode;                 /* Operation type */
    unsigned int            send_flags;             /* Flags of the WR properties */
    union {
    __be32                  imm_data;               /* Immediate data (in network byte order) */
    uint32_t                invalidate_rkey;        /* Remote rkey to invalidate */
    };
    union {
    struct {
    uint64_t        remote_addr;    /* Start address of remote memory buffer */
    uint32_t        rkey;           /* Key of the remote Memory Region */
    } rdma;
    struct {
    uint64_t        remote_addr;    /* Start address of remote memory buffer */ 
    uint64_t        compare_add;    /* Compare operand */
    uint64_t        swap;           /* Swap operand */
    uint32_t        rkey;           /* Key of the remote Memory Region */
    } atomic;
    struct {
    struct ibv_ah  *ah;             /* Address handle (AH) for the remote node address */
    uint32_t        remote_qpn;     /* QP number of the destination QP */
    uint32_t        remote_qkey;    /* Q_Key number of the destination QP */
    } ud;
    } wr;
    union {
    struct {
    uint32_t remote_srqn;            /* Number of the remote SRQ */
    } xrc;
    } qp_type;
    union {
    struct {
    struct ibv_mw            *mw;             /* Memory window (MW) of type 2 to bind */
    uint32_t                 rkey;            /* The desired new rkey of the MW */
    struct ibv_mw_bind_info  bind_info;       /* MW additional bind information */
    } bind_mw;
    struct {
    void			*hdr;	/* Pointer address of inline header */
    uint16_t		hdr_sz;	/* Inline header size */
    uint16_t		mss;	/* Maximum segment size for each TSO fragment */
    } tso;
    };
    };

    struct ibv_mw_bind_info {
    struct ibv_mr            *mr;             /* The Memory region (MR) to bind the MW to */
    uint64_t                 addr;           /* The address the MW should start at */
    uint64_t                 length;          /* The length (in bytes) the MW should span */
    unsigned int             mw_access_flags; /* Access flags to the MW. Use ibv_access_flags */
    };

    struct ibv_sge {
    uint64_t                addr;                   /* Start address of the local memory buffer or number of bytes from the
                                                       start of the MR for MRs which are IBV_ACCESS_ZERO_BASED */
    uint32_t                length;                 /* Length of the buffer */
    uint32_t                lkey;                   /* Key of the local Memory Region */
    };

Each QP Transport Service Type supports a specific set of opcodes, as
shown in the following table:

    OPCODE                      | IBV_QPT_UD | IBV_QPT_UC | IBV_QPT_RC | IBV_QPT_XRC_SEND | IBV_QPT_RAW_PACKET
    ----------------------------+------------+------------+------------+------------------+--------------------
    IBV_WR_SEND                 |     X      |     X      |     X      |         X        |         X
    IBV_WR_SEND_WITH_IMM        |     X      |     X      |     X      |         X        |
    IBV_WR_RDMA_WRITE           |            |     X      |     X      |         X        |
    IBV_WR_RDMA_WRITE_WITH_IMM  |            |     X      |     X      |         X        |
    IBV_WR_RDMA_READ            |            |            |     X      |         X        |
    IBV_WR_ATOMIC_CMP_AND_SWP   |            |            |     X      |         X        |
    IBV_WR_ATOMIC_FETCH_AND_ADD |            |            |     X      |         X        |
    IBV_WR_LOCAL_INV            |            |     X      |     X      |         X        |
    IBV_WR_BIND_MW              |            |     X      |     X      |         X        |
    IBV_WR_SEND_WITH_INV        |            |     X      |     X      |         X        |
    IBV_WR_TSO                  |     X      |            |            |                  |         X

The attribute send_flags describes the properties of the WR. It is
either 0 or the bitwise OR of one or more of the following flags:

**IBV_SEND_FENCE Set the fence indicator. Valid only for QPs with Transport Service Type **IBV_QPT_RC****

:   

    **IBV_SEND_SIGNALED Set the completion notification indicator. Relevant only if QP was created with sq_sig_all=0**

    :   

        **IBV_SEND_SOLICITED Set the solicited event indicator. Valid only for Send and RDMA Write with immediate**

        :   

            **IBV_SEND_INLINE Send data in given gather list as inline data**

            :   in a send WQE. Valid only for Send and RDMA Write. The
                L_Key will not be checked.

            **IBV_SEND_IP_CSUM Offload the IPv4 and TCP/UDP checksum calculation.**

            :   Valid only when **device_cap_flags** in device_attr
                indicates current QP is supported by checksum offload.

# RETURN VALUE

**ibv_post_send()** returns 0 on success, or the value of errno on
failure (which indicates the failure reason).

# NOTES

The user should not alter or destroy AHs associated with WRs until
request is fully executed and a work completion has been retrieved from
the corresponding completion queue (CQ) to avoid unexpected behavior.

The buffers used by a WR can only be safely reused after WR the request
is fully executed and a work completion has been retrieved from the
corresponding completion queue (CQ). However, if the IBV_SEND_INLINE
flag was set, the buffer can be reused immediately after the call
returns.

IBV_WR_DRIVER1 is an opcode that should be used to issue a specific
driver operation.

# SEE ALSO

**ibv_create_qp**(3), **ibv_create_ah**(3), **ibv_post_recv**(3),
**ibv_post_srq_recv**(3), **ibv_poll_cq**(3)

# AUTHORS

Dotan Barak \<dotanba@gmail.com\>

:   

    Majd Dibbiny \<majd@mellanox.com\>

    :   

Yishai Hadas \<yishaih@mellanox.com\>

请确保描述简洁明了，适合放在verbs.py中。输出中只需要含有python代码本身即可，无需含有说明性文字。