请补全以下函数对应的verb描述（用在verbs.py中）：

- ibv_query_qp_data_in_order

请直接生成python代码，我之后会自行添加到verbs.py中。
函数详细信息：
Function Name: ibv_query_qp_data_in_order
Output:
int ibv_query_qp_data_in_order(struct ibv_qp * qp, enum ibv_wr_opcode op, uint32_t flags);
struct ibv_qp {
    struct ibv_context * context;
    struct ibv_context {
        struct ibv_device * device;
        struct ibv_device {
            struct _ibv_device_ops _ops;
            struct _ibv_device_ops {
                struct ibv_context *(*)(struct ibv_device *, int) _dummy1;
                void (*)(struct ibv_context *) _dummy2;
            };
            enum ibv_node_type node_type;
            enum ibv_node_type {
                IBV_NODE_UNKNOWN = -1,
                IBV_NODE_CA = 1,
                IBV_NODE_SWITCH = 2,
                IBV_NODE_ROUTER = 3,
                IBV_NODE_RNIC = 4,
                IBV_NODE_USNIC = 5,
                IBV_NODE_USNIC_UDP = 6,
                IBV_NODE_UNSPECIFIED = 7,
            };
            enum ibv_transport_type transport_type;
            enum ibv_transport_type {
                IBV_TRANSPORT_UNKNOWN = -1,
                IBV_TRANSPORT_IB = 0,
                IBV_TRANSPORT_IWARP = 1,
                IBV_TRANSPORT_USNIC = 2,
                IBV_TRANSPORT_USNIC_UDP = 3,
                IBV_TRANSPORT_UNSPECIFIED = 4,
            };
            char[64] name;
            char[64] dev_name;
            char[256] dev_path;
            char[256] ibdev_path;
        };
        struct ibv_context_ops ops;
        struct ibv_context_ops {
            int (*)(struct ibv_context *, struct ibv_device_attr *) _compat_query_device;
            int (*)(struct ibv_context *, uint8_t, struct _compat_ibv_port_attr *) _compat_query_port;
            void *(*)(void) _compat_alloc_pd;
            void *(*)(void) _compat_dealloc_pd;
            void *(*)(void) _compat_reg_mr;
            void *(*)(void) _compat_rereg_mr;
            void *(*)(void) _compat_dereg_mr;
            struct ibv_mw *(*)(struct ibv_pd *, enum ibv_mw_type) alloc_mw;
            int (*)(struct ibv_qp *, struct ibv_mw *, struct ibv_mw_bind *) bind_mw;
            int (*)(struct ibv_mw *) dealloc_mw;
            void *(*)(void) _compat_create_cq;
            int (*)(struct ibv_cq *, int, struct ibv_wc *) poll_cq;
            int (*)(struct ibv_cq *, int) req_notify_cq;
            void *(*)(void) _compat_cq_event;
            void *(*)(void) _compat_resize_cq;
            void *(*)(void) _compat_destroy_cq;
            void *(*)(void) _compat_create_srq;
            void *(*)(void) _compat_modify_srq;
            void *(*)(void) _compat_query_srq;
            void *(*)(void) _compat_destroy_srq;
            int (*)(struct ibv_srq *, struct ibv_recv_wr *, struct ibv_recv_wr **) post_srq_recv;
            void *(*)(void) _compat_create_qp;
            void *(*)(void) _compat_query_qp;
            void *(*)(void) _compat_modify_qp;
            void *(*)(void) _compat_destroy_qp;
            int (*)(struct ibv_qp *, struct ibv_send_wr *, struct ibv_send_wr **) post_send;
            int (*)(struct ibv_qp *, struct ibv_recv_wr *, struct ibv_recv_wr **) post_recv;
            void *(*)(void) _compat_create_ah;
            void *(*)(void) _compat_destroy_ah;
            void *(*)(void) _compat_attach_mcast;
            void *(*)(void) _compat_detach_mcast;
            void *(*)(void) _compat_async_event;
        };
        int cmd_fd;
        int async_fd;
        int num_comp_vectors;
        pthread_mutex_t mutex;
        void * abi_compat;
    };
    void * qp_context;
    struct ibv_pd * pd;
    struct ibv_pd {
        struct ibv_context * context;
        uint32_t handle;
    };
    struct ibv_cq * send_cq;
    struct ibv_cq {
        struct ibv_context * context;
        struct ibv_comp_channel * channel;
        struct ibv_comp_channel {
            struct ibv_context * context;
            int fd;
            int refcnt;
        };
        void * cq_context;
        uint32_t handle;
        int cqe;
        pthread_mutex_t mutex;
        pthread_cond_t cond;
        uint32_t comp_events_completed;
        uint32_t async_events_completed;
    };
    struct ibv_cq * recv_cq;
    struct ibv_srq * srq;
    struct ibv_srq {
        struct ibv_context * context;
        void * srq_context;
        struct ibv_pd * pd;
        uint32_t handle;
        pthread_mutex_t mutex;
        pthread_cond_t cond;
        uint32_t events_completed;
    };
    uint32_t handle;
    uint32_t qp_num;
    enum ibv_qp_state state;
    enum ibv_qp_state {
        IBV_QPS_RESET = 0,
        IBV_QPS_INIT = 1,
        IBV_QPS_RTR = 2,
        IBV_QPS_RTS = 3,
        IBV_QPS_SQD = 4,
        IBV_QPS_SQE = 5,
        IBV_QPS_ERR = 6,
        IBV_QPS_UNKNOWN = 7,
    };
    enum ibv_qp_type qp_type;
    enum ibv_qp_type {
        IBV_QPT_RC = 2,
        IBV_QPT_UC = 3,
        IBV_QPT_UD = 4,
        IBV_QPT_RAW_PACKET = 8,
        IBV_QPT_XRC_SEND = 9,
        IBV_QPT_XRC_RECV = 10,
        IBV_QPT_DRIVER = 255,
    };
    pthread_mutex_t mutex;
    pthread_cond_t cond;
    uint32_t events_completed;
};
enum ibv_wr_opcode {
    IBV_WR_RDMA_WRITE = 0,
    IBV_WR_RDMA_WRITE_WITH_IMM = 1,
    IBV_WR_SEND = 2,
    IBV_WR_SEND_WITH_IMM = 3,
    IBV_WR_RDMA_READ = 4,
    IBV_WR_ATOMIC_CMP_AND_SWP = 5,
    IBV_WR_ATOMIC_FETCH_AND_ADD = 6,
    IBV_WR_LOCAL_INV = 7,
    IBV_WR_BIND_MW = 8,
    IBV_WR_SEND_WITH_INV = 9,
    IBV_WR_TSO = 10,
    IBV_WR_DRIVER1 = 11,
    IBV_WR_FLUSH = 14,
    IBV_WR_ATOMIC_WRITE = 15,
};

函数相关文档：
---
date: 2020-3-3
footer: libibverbs
header: "Libibverbs Programmer's Manual"
layout: page
license: 'Licensed under the OpenIB.org BSD license (FreeBSD Variant) - See COPYING.md'
section: 3
title: ibv_query_qp_data_in_order
---

# NAME

ibv_query_qp_data_in_order - check if qp data is guaranteed to be in order.

# SYNOPSIS

```c
#include <infiniband/verbs.h>

int ibv_query_qp_data_in_order(struct ibv_qp *qp, enum ibv_wr_opcode op, uint32_t flags);

```


# DESCRIPTION

**ibv_query_qp_data_in_order()** Checks whether WQE data is guaranteed to be
written in-order, and thus reader may poll for data instead of poll for completion.
This function indicates data is written in-order within each WQE, but cannot be used to determine ordering between separate WQEs.
This function describes ordering at the receiving side of the QP, not the sending side.

# ARGUMENTS
*qp*
:       The local queue pair (QP) to query.

*op*
:       The operation type to query about. Different operation types may write data in a different order.
	For RDMA read operations: describes ordering of RDMA reads posted on this local QP.
	For RDMA write operations: describes ordering of remote RDMA writes being done into this local QP.
	For RDMA send operations: describes ordering of remote RDMA sends being done into this local QP.
	This function should not be used to determine ordering of other operation types.

*flags*
:	Flags are used to select a query type. Supported values:

IBV_QUERY_QP_DATA_IN_ORDER_RETURN_CAPS - Query for supported capabilities and return a capabilities vector.

Passing 0 is equivalent to using IBV_QUERY_QP_DATA_IN_ORDER_RETURN_CAPS and checking for IBV_QUERY_QP_DATA_IN_ORDER_WHOLE_MSG support.

# RETURN VALUE

**ibv_query_qp_data_in_order()** Return value is determined by flags. For each capability bit, 1 is returned if the data is guaranteed to be written in-order for selected operation and type, 0 otherwise.
If IBV_QUERY_QP_DATA_IN_ORDER_RETURN_CAPS flag is used, return value can consist of following capabilities:

IBV_QUERY_QP_DATA_IN_ORDER_WHOLE_MSG - All data is being written in order.

IBV_QUERY_QP_DATA_IN_ORDER_ALIGNED_128_BYTES - Each 128 bytes aligned block is being written in order.

If flags is 0, the function will return 1 if IBV_QUERY_QP_DATA_IN_ORDER_WHOLE_MSG is supported and 0 otherwise.

# NOTES

Return value is valid only when the data is read by the CPU and relaxed ordering MR is not the target of the transfer.

# SEE ALSO

**ibv_query_qp**(3)

# AUTHOR

Patrisious Haddad <phaddad@nvidia.com>

Yochai Cohen <yochai@nvidia.com>

请确保描述简洁明了，适合放在verbs.py中。输出中只需要含有python代码本身即可，无需含有说明性文字。